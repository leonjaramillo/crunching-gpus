{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b5ccd3-c57a-4af9-aaef-1ba4a41c490b",
   "metadata": {},
   "source": [
    "Be sure to install PyTorch with CUDA support in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b6a37-c6a2-4bd1-a00d-dd49893a85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503705b4-dfb1-4c34-998b-b0347902127c",
   "metadata": {},
   "source": [
    "Afterwards, you might better verify your PyTorch installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffafc82-ed45-4e68-a107-ce95a060085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4a31a-9f47-4587-9eec-12e742a61826",
   "metadata": {},
   "source": [
    "Let's set-up some common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8644634-4403-46df-a81e-9ee9e206fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3            \n",
    "STEPS_PER_EPOCH = 1000  \n",
    "BATCH_SIZE = 4096       \n",
    "FEATURES = 256\n",
    "CLASSES = 10\n",
    "HIDDEN = 512\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ad94b-8d3a-4b52-9ca2-2a982a2089d4",
   "metadata": {},
   "source": [
    "The code below runs a basic PyTorch training job without using the GPU. You indicate it through **device**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ce238-c349-48d1-872e-c3b6e4f49df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "USE_CUDA = False and torch.cuda.is_available()  # set to True to use your GPU\n",
    "\n",
    "device = torch.device(\"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# tiny MLP\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(FEATURES, HIDDEN),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(HIDDEN, CLASSES),\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_start = time.perf_counter()\n",
    "    loss_accum = 0.0\n",
    "\n",
    "    for step in range(1, STEPS_PER_EPOCH + 1):\n",
    "        # generate synthetic batch on the fly (no I/O, keeps code simple)\n",
    "        xb = torch.randn(BATCH_SIZE, FEATURES, device=device)\n",
    "        yb = torch.randint(0, CLASSES, (BATCH_SIZE,), device=device)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "\n",
    "        # occasional heartbeat so you can see progress\n",
    "        if step % 500 == 0 or step == STEPS_PER_EPOCH:\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            print(f\"epoch {epoch}/{EPOCHS}  step {step}/{STEPS_PER_EPOCH}  \"\n",
    "                  f\"loss {loss_accum/step:.4f}  elapsed {elapsed:.1f}s\", flush=True)\n",
    "\n",
    "    print(f\"epoch {epoch} done in {time.perf_counter() - epoch_start:.1f}s\")\n",
    "\n",
    "print(\"total time:\", round(time.perf_counter() - t0, 1), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012746e-6b1c-401d-b223-64545c2427a5",
   "metadata": {},
   "source": [
    "Before trying to use the GPU, be sure that it is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc29e07-529d-48e8-9611-905d4f09b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbe2a0-4320-41bf-9a66-8b5dcbb72531",
   "metadata": {},
   "source": [
    "Then, we must check that CUDA is installed. If not, there is a custom way for each OS in the NVIDIA site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a58081-9b2b-45ee-a88f-65a2674a14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca75929-93aa-4bfe-85c2-adc0d6ebbbda",
   "metadata": {},
   "source": [
    "Now, it's time to use the GPU (and compare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8a86b-bc89-42eb-afd9-9322e5b3cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "USE_CUDA = True and torch.cuda.is_available()  # set to True to use your GPU\n",
    "\n",
    "device = torch.device(\"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# tiny MLP\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(FEATURES, HIDDEN),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(HIDDEN, CLASSES),\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_start = time.perf_counter()\n",
    "    loss_accum = 0.0\n",
    "\n",
    "    for step in range(1, STEPS_PER_EPOCH + 1):\n",
    "        # generate synthetic batch on the fly (no I/O, keeps code simple)\n",
    "        xb = torch.randn(BATCH_SIZE, FEATURES, device=device)\n",
    "        yb = torch.randint(0, CLASSES, (BATCH_SIZE,), device=device)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "\n",
    "        # occasional heartbeat so you can see progress\n",
    "        if step % 500 == 0 or step == STEPS_PER_EPOCH:\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            print(f\"epoch {epoch}/{EPOCHS}  step {step}/{STEPS_PER_EPOCH}  \"\n",
    "                  f\"loss {loss_accum/step:.4f}  elapsed {elapsed:.1f}s\", flush=True)\n",
    "\n",
    "    print(f\"epoch {epoch} done in {time.perf_counter() - epoch_start:.1f}s\")\n",
    "\n",
    "print(\"total time:\", round(time.perf_counter() - t0, 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162855fe-15dc-4764-86e7-01a855f10bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
